{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuthKassahun/Brain_Tissue_Segmentation/blob/main/2D_unet_4versions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKu0jOnLpdmS",
        "outputId": "b5d59fea-d5d5-4072-9222-b5c7db9c7b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: simpleitk in /usr/local/lib/python3.8/dist-packages (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import warnings\n",
        "import scipy.misc\n",
        "!pip install simpleitk\n",
        "import SimpleITK as sitk\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import warnings\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "!pip install simpleitk\n",
        "import SimpleITK as sitk\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4d_0hoJDN5m",
        "outputId": "6b472b48-2ef8-4a70-eb3c-107ddada7d60"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: simpleitk in /usr/local/lib/python3.8/dist-packages (2.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU_RRQswplFz",
        "outputId": "9023082a-e518-4fc7-d4af-7867fbd3a6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEw0FQgYSMTt",
        "outputId": "6c32061d-71c3-469c-8676-f0b2fd38cba0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_unet_collection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBhOH8eC9Lnz",
        "outputId": "aabab1fc-5cd3-414f-ac07-8f9fa606934f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_unet_collection\n",
            "  Downloading keras_unet_collection-0.1.13-py3-none-any.whl (67 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_unet_collection\n",
            "Successfully installed keras_unet_collection-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Input"
      ],
      "metadata": {
        "id": "e2qy01scBJrw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet(img_size=PATCH_SIZE, n_classes=N_CLASSES, n_input_channels=N_INPUT_CHANNELS, scale=1):\n",
        "    inputs = keras.Input(shape=img_size + (n_input_channels, ))\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
        "    max1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(max1)\n",
        "    max2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(max2)\n",
        "    max3 = layers.MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    lat = layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(max3)\n",
        "\n",
        "    # Decoding path\n",
        "    up1 = layers.UpSampling2D((2, 2))(lat)\n",
        "    concat1 = layers.concatenate([conv3, up1], axis=-1)\n",
        "    conv4 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(concat1)\n",
        "    \n",
        "    up2 = layers.UpSampling2D((2, 2))(conv4)\n",
        "    concat2 = layers.concatenate([conv2, up2], axis=-1)\n",
        "    conv5 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(concat2)\n",
        "    \n",
        "    up3 = layers.UpSampling2D((2, 2))(conv5)\n",
        "    concat3 = layers.concatenate([conv1, up3], axis=-1)\n",
        "\n",
        "    conv6 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(concat3)\n",
        "\n",
        "    outputs = layers.Conv2D(n_classes, (1, 1), activation=\"softmax\")(conv6)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HTAwQT0zAj4u"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet2(img_size=PATCH_SIZE, n_classes=N_CLASSES, n_input_channels=N_INPUT_CHANNELS, scale=1):\n",
        "    inputs = keras.Input(shape=img_size + (n_input_channels, ))\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
        "    max1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(max1)\n",
        "    max2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(max2)\n",
        "    max3 = layers.MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(max3)\n",
        "    max4 = layers.MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "    lat = layers.Conv2D(512*scale, (3, 3), padding=\"same\", activation='relu')(max4)\n",
        "\n",
        "    # Decoding path\n",
        "    up1 = layers.UpSampling2D((2, 2))(lat)\n",
        "    concat1 = layers.concatenate([conv4, up1], axis=-1)\n",
        "    conv5 = layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(concat1)\n",
        "    \n",
        "    up2 = layers.UpSampling2D((2, 2))(conv5)\n",
        "    concat2 = layers.concatenate([conv3, up2], axis=-1)\n",
        "    conv6 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(concat2)\n",
        "    \n",
        "    up3 = layers.UpSampling2D((2, 2))(conv6)\n",
        "    concat3 = layers.concatenate([conv2, up3], axis=-1)\n",
        "    conv7 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(concat3)\n",
        "\n",
        "    up4 = layers.UpSampling2D((2, 2))(conv7)\n",
        "    concat4 = layers.concatenate([conv1, up4], axis=-1)\n",
        "    conv8 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(concat4)\n",
        "\n",
        "    outputs = layers.Conv2D(n_classes, (1, 1), activation=\"softmax\")(conv8)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "_yyhi9UIiMnS"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet3(img_size=PATCH_SIZE, n_classes=N_CLASSES, n_input_channels=N_INPUT_CHANNELS, scale=1):\n",
        "    inputs = keras.Input(shape=img_size + (n_input_channels, ))\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
        "    drop1 = layers.Dropout(rate=dropout_rate)(conv1, training=True)\n",
        "    max1 = layers.MaxPooling2D((2, 2))(drop1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(max1)\n",
        "    drop2 = layers.Dropout(rate=dropout_rate)(conv2, training=True)\n",
        "    max2 = layers.MaxPooling2D((2, 2))(drop2)\n",
        "\n",
        "    conv3 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(max2)\n",
        "    drop3 = layers.Dropout(rate=dropout_rate)(conv3, training=True)\n",
        "    max3 = layers.MaxPooling2D((2, 2))(drop3)\n",
        "\n",
        "    conv4 = layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(max3)\n",
        "    drop4 = layers.Dropout(rate=dropout_rate)(conv4, training=True)\n",
        "    max4 = layers.MaxPooling2D((2, 2))(drop4)\n",
        "\n",
        "    lat = layers.Conv2D(512*scale, (3, 3), padding=\"same\", activation='relu')(max4)\n",
        "    drop5 = layers.Dropout(rate=dropout_rate)(lat, training=True)\n",
        "\n",
        "    # Decoding path\n",
        "    up1 = layers.UpSampling2D((2, 2))(drop5)\n",
        "    concat1 = layers.concatenate([conv4, up1], axis=-1)\n",
        "    conv5 = layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(concat1)\n",
        "    drop6 = layers.Dropout(rate=dropout_rate)(conv5, training=True)\n",
        "    \n",
        "    up2 = layers.UpSampling2D((2, 2))(drop6)\n",
        "    concat2 = layers.concatenate([conv3, up2], axis=-1)\n",
        "    conv6 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(concat2)\n",
        "    drop7 = layers.Dropout(rate=dropout_rate)(conv6, training=True)\n",
        "    \n",
        "    up3 = layers.UpSampling2D((2, 2))(drop7)\n",
        "    concat3 = layers.concatenate([conv2, up3], axis=-1)\n",
        "    conv7 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(concat3)\n",
        "    drop8 = layers.Dropout(rate=dropout_rate)(conv7, training=True)\n",
        "\n",
        "    up4 = layers.UpSampling2D((2, 2))(drop8)\n",
        "    concat4 = layers.concatenate([conv1, up4], axis=-1)\n",
        "    conv8 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(concat4)\n",
        "    drop9 = layers.Dropout(rate=dropout_rate)(conv8, training=True)\n",
        "\n",
        "    outputs = layers.Conv2D(n_classes, (1, 1), activation=\"softmax\")(conv8)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8gSP4c7tmWVG"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet4(img_size=PATCH_SIZE, n_classes=N_CLASSES, n_input_channels=N_INPUT_CHANNELS, scale=1):\n",
        "    inputs = keras.Input(shape=img_size + (n_input_channels, ))\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = layers.BatchNormalization()(layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(inputs))\n",
        "    drop1 = layers.Dropout(rate=dropout_rate)(conv1, training=True)\n",
        "    max1 = layers.MaxPooling2D((2, 2))(drop1)\n",
        "\n",
        "    conv2 = layers.BatchNormalization()(layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(max1))\n",
        "    drop2 = layers.Dropout(rate=dropout_rate)(conv2, training=True)\n",
        "    max2 = layers.MaxPooling2D((2, 2))(drop2)\n",
        "\n",
        "    conv3 = layers.BatchNormalization()(layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(max2))\n",
        "    drop3 = layers.Dropout(rate=dropout_rate)(conv3, training=True)\n",
        "    max3 = layers.MaxPooling2D((2, 2))(drop3)\n",
        "\n",
        "    conv4 = layers.BatchNormalization()(layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(max3))\n",
        "    drop4 = layers.Dropout(rate=dropout_rate)(conv4, training=True)\n",
        "    max4 = layers.MaxPooling2D((2, 2))(drop4)\n",
        "\n",
        "    lat = layers.BatchNormalization()(layers.Conv2D(512*scale, (3, 3), padding=\"same\", activation='relu')(max4))\n",
        "    drop5 = layers.Dropout(rate=dropout_rate)(lat, training=True)\n",
        "\n",
        "    # Decoding path\n",
        "    up1 = layers.UpSampling2D((2, 2))(drop5)\n",
        "    concat1 = layers.concatenate([conv4, up1], axis=-1)\n",
        "    conv5 = layers.BatchNormalization()(layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(concat1))\n",
        "    drop6 = layers.Dropout(rate=dropout_rate)(conv5, training=True)\n",
        "    \n",
        "    up2 = layers.UpSampling2D((2, 2))(drop6)\n",
        "    concat2 = layers.concatenate([conv3, up2], axis=-1)\n",
        "    conv6 = layers.BatchNormalization()(layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(concat2))\n",
        "    drop7 = layers.Dropout(rate=dropout_rate)(conv6, training=True)\n",
        "    \n",
        "    up3 = layers.UpSampling2D((2, 2))(drop7)\n",
        "    concat3 = layers.concatenate([conv2, up3], axis=-1)\n",
        "    conv7 = layers.BatchNormalization()(layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(concat3))\n",
        "    drop8 = layers.Dropout(rate=dropout_rate)(conv7, training=True)\n",
        "\n",
        "    up4 = layers.UpSampling2D((2, 2))(drop8)\n",
        "    concat4 = layers.concatenate([conv1, up4], axis=-1)\n",
        "    conv8 = layers.BatchNormalization()(layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(concat4))\n",
        "    drop9 = layers.Dropout(rate=dropout_rate)(conv8, training=True)\n",
        "\n",
        "    outputs = layers.Conv2D(n_classes, (1, 1), activation=\"softmax\")(conv8)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "a1B6bxt8xnid"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install focal_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImLqMhdEcuTU",
        "outputId": "fb56eb20-ca79-4c18-f652-38ff74851238"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting focal_loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.8/dist-packages (from focal_loss) (2.9.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (4.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (14.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (0.29.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (1.51.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (2.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2->focal_loss) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (0.6.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.2->focal_loss) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (5.2.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.2->focal_loss) (3.2.2)\n",
            "Installing collected packages: focal_loss\n",
            "Successfully installed focal_loss-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from focal_loss import BinaryFocalLoss"
      ],
      "metadata": {
        "id": "fNBdOnBPcsoz"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from focal_loss import sparse_categorical_focal_loss"
      ],
      "metadata": {
        "id": "wMl47Zb2dqbD"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "eeYOrqTfpqRJ"
      },
      "outputs": [],
      "source": [
        "FNAME_PATTERN = '/content/drive/MyDrive/MISA_Final_project/IBSR-{}-{}.nii'\n",
        "N_VOLUMES = 15\n",
        "IMAGE_SIZE = (256, 128, 256)\n",
        "\n",
        "# network parameters\n",
        "N_CLASSES = 4\n",
        "N_INPUT_CHANNELS = 1\n",
        "PATCH_SIZE = (32, 32)\n",
        "PATCH_STRIDE = (32, 32)\n",
        "\n",
        "# training, validation, test parameters\n",
        "TRAINING_VOLUMES = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "VALIDATION_VOLUMES = [10, 11, 12, 13, 14]\n",
        "#TEST_VOLUMES = [14]\n",
        "\n",
        "\n",
        "# data preparation parameters\n",
        "CONTENT_THRESHOLD = 0.3\n",
        "\n",
        "# training parameters\n",
        "N_EPOCHS = 500\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 20\n",
        "MODEL_FNAME_PATTERN = 'model_v3.h5'\n",
        "# OPTIMISER = 'Adam'\n",
        "learning_rate=0.0001\n",
        "OPTIMISER = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
        "# OPTIMISER = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate)\n",
        "LOSS = 'categorical_crossentropy'\n",
        "# LOSS ='sparse_categorical_crossentropy'\n",
        "# LOSS = tfa.losses.GIoULoss()\n",
        "#LOSS = BinaryFocalLoss(gamma=2)\n",
        "# LOSS = sparse_categorical_focal_loss(from_logits=False, class_weight=[0.1, 0.9, 1, 1])\n",
        "\n",
        "# LOSS = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "dropout_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "SJnPts_nqol7"
      },
      "outputs": [],
      "source": [
        "def load_data(n_volumes=N_VOLUMES, image_size=IMAGE_SIZE, fname_pattern=FNAME_PATTERN) :\n",
        "  T1_volumes = np.zeros((n_volumes, *image_size, 1))\n",
        "  #T2_volumes = np.zeros((n_volumes, *image_size, 1))\n",
        "  labels = np.zeros((n_volumes, *image_size, 1))\n",
        "  for i in range(n_volumes) :\n",
        "    img_data = nib.load(fname_pattern.format(i+1, 'T1'))\n",
        "    T1_volumes[i] = img_data.get_fdata()\n",
        "\n",
        "    # img_data = nib.load(fname_pattern.format(i+1, 'T2'))\n",
        "    # T2_volumes[i] = img_data.get_fdata()\n",
        "\n",
        "    seg_data = nib.load(fname_pattern.format(i+1, 'label'))\n",
        "    labels[i] = seg_data.get_fdata()\n",
        "\n",
        "  return (T1_volumes, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "lPPthE1-qrPh"
      },
      "outputs": [],
      "source": [
        "(T1_volumes, labels) = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "eElM97nKrtO8"
      },
      "outputs": [],
      "source": [
        "training_volumes_T1 = T1_volumes[TRAINING_VOLUMES]\n",
        "#training_volumes_T2 = T2_volumes[TRAINING_VOLUMES]\n",
        "training_labels = labels[TRAINING_VOLUMES]\n",
        "\n",
        "validation_volumes_T1 = T1_volumes[VALIDATION_VOLUMES]\n",
        "#validation_volumes_T2 = T2_volumes[VALIDATION_VOLUMES]\n",
        "validation_labels = labels[VALIDATION_VOLUMES]\n",
        "\n",
        "#testing_volumes_T1 = T1_volumes[TEST_VOLUMES]\n",
        "#testing_volumes_T2 = T2_volumes[TEST_VOLUMES]\n",
        "#testing_labels = labels[TEST_VOLUMES]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "K6zNRpANrvVd"
      },
      "outputs": [],
      "source": [
        "def extract_patches(x, patch_size, patch_stride) :\n",
        "  return tf.image.extract_patches(\n",
        "    x,\n",
        "    sizes=[1, *patch_size, 1],\n",
        "    strides=[1, *patch_stride, 1],\n",
        "    rates=[1, 1, 1, 1],\n",
        "    padding='SAME', name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "CDf7cEGxrxd8"
      },
      "outputs": [],
      "source": [
        "def extract_useful_patches(\n",
        "    volumes, labels,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    patch_size=PATCH_SIZE,\n",
        "    stride=PATCH_STRIDE,\n",
        "    threshold=CONTENT_THRESHOLD,\n",
        "    num_classes=N_CLASSES) :\n",
        "  volumes = volumes.reshape([-1, image_size[1], image_size[2], 1])\n",
        "  labels = labels.reshape([-1, image_size[1], image_size[2], 1])\n",
        "\n",
        "\n",
        "  vol_patches = extract_patches(volumes, patch_size, stride).numpy()\n",
        "  seg_patches = extract_patches(labels, patch_size, stride).numpy()\n",
        "  \n",
        "  vol_patches = vol_patches.reshape([-1, *patch_size, 1])\n",
        "  seg_patches = seg_patches.reshape([-1, *patch_size, ])\n",
        "\n",
        "  foreground_mask = seg_patches != 0 \n",
        "\n",
        "  useful_patches = foreground_mask.sum(axis=(1, 2)) > threshold * np.prod(patch_size)\n",
        "\n",
        "  vol_patches = vol_patches[useful_patches]\n",
        "  seg_patches = seg_patches[useful_patches]\n",
        "  print(np.unique(seg_patches))\n",
        "  seg_patches = tf.keras.utils.to_categorical(seg_patches, num_classes=N_CLASSES, dtype='float32')\n",
        "  \n",
        "  print(np.unique(seg_patches))\n",
        "  return (vol_patches, seg_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "hdk1hs_Zr0M3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d3b6c2-005a-44de-b1eb-6130cb983798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 2. 3.]\n",
            "[0. 1.]\n",
            "[0. 1. 2. 3.]\n",
            "[0. 1.]\n"
          ]
        }
      ],
      "source": [
        "# extract patches from training set\n",
        "(training_patches_T1, training_patches_seg) = extract_useful_patches(training_volumes_T1, training_labels)\n",
        "#(training_patches_T2, _) = extract_useful_patches(training_volumes_T2, training_labels)\n",
        "\n",
        "# extract patches from validation set\n",
        "(validation_patches_T1, validation_patches_seg) = extract_useful_patches(validation_volumes_T1, validation_labels)\n",
        "#(validation_patches_T2, _) = extract_useful_patches(validation_volumes_T2, validation_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.dstack([training_patches_T1] * 3)\n",
        "X_train = X_train.reshape(-1, 32,32,3)\n",
        "# X_train = np.rollaxis(X_train, 3, 1)\n",
        "\n",
        "X_val=np.dstack([validation_patches_T1] * 3)\n",
        "X_val= X_val.reshape(-1, 32,32,3)\n",
        "# X_val = np.rollaxis(X_val, 3, 1)\n",
        "print(validation_patches_T1.shape)\n",
        "print(X_val.shape)\n",
        "\n",
        "print(training_patches_T1.shape)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xu-inJpxRGS",
        "outputId": "5fba11d5-c554-41ce-d0cc-3533875ca42c"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6648, 32, 32, 1)\n",
            "(6648, 32, 32, 3)\n",
            "(12747, 32, 32, 1)\n",
            "(12747, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=PATIENCE), # early stopping\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=MODEL_FNAME_PATTERN, save_best_only=True) # save the best based on validation\n",
        "]\n",
        "\n",
        "unet = get_unet4()\n",
        "unet.compile(optimizer=OPTIMISER, loss=LOSS, \n",
        "             metrics=tf.keras.metrics.MeanIoU(num_classes=4)\n",
        "            )\n",
        "unet.fit(\n",
        "    x=training_patches_T1,\n",
        "    # x=X_train, \n",
        "    y=training_patches_seg,\n",
        "    # validation_data=(X_val, validation_patches_seg),\n",
        "    validation_data=(validation_patches_T1, validation_patches_seg),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=500,\n",
        "    callbacks=my_callbacks,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6g1Q2L3Ar1x",
        "outputId": "0dd150a3-921f-4fff-f849-aa8068de8cfc"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "399/399 [==============================] - 7s 14ms/step - loss: 0.4352 - mean_io_u_21: 0.3750 - val_loss: 0.6703 - val_mean_io_u_21: 0.3779\n",
            "Epoch 2/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.3055 - mean_io_u_21: 0.3750 - val_loss: 0.5894 - val_mean_io_u_21: 0.3775\n",
            "Epoch 3/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.2771 - mean_io_u_21: 0.3750 - val_loss: 0.5337 - val_mean_io_u_21: 0.3777\n",
            "Epoch 4/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.2543 - mean_io_u_21: 0.3750 - val_loss: 0.5079 - val_mean_io_u_21: 0.3786\n",
            "Epoch 5/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.2396 - mean_io_u_21: 0.3750 - val_loss: 0.6551 - val_mean_io_u_21: 0.3807\n",
            "Epoch 6/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.2282 - mean_io_u_21: 0.3750 - val_loss: 0.6677 - val_mean_io_u_21: 0.3818\n",
            "Epoch 7/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.2187 - mean_io_u_21: 0.3750 - val_loss: 0.7245 - val_mean_io_u_21: 0.3863\n",
            "Epoch 8/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.2109 - mean_io_u_21: 0.3750 - val_loss: 0.6579 - val_mean_io_u_21: 0.3854\n",
            "Epoch 9/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.2049 - mean_io_u_21: 0.3750 - val_loss: 0.7814 - val_mean_io_u_21: 0.3895\n",
            "Epoch 10/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1972 - mean_io_u_21: 0.3750 - val_loss: 0.8221 - val_mean_io_u_21: 0.3940\n",
            "Epoch 11/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1922 - mean_io_u_21: 0.3750 - val_loss: 0.8836 - val_mean_io_u_21: 0.3964\n",
            "Epoch 12/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1883 - mean_io_u_21: 0.3750 - val_loss: 0.9057 - val_mean_io_u_21: 0.3989\n",
            "Epoch 13/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1837 - mean_io_u_21: 0.3750 - val_loss: 0.8776 - val_mean_io_u_21: 0.3978\n",
            "Epoch 14/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.1810 - mean_io_u_21: 0.3750 - val_loss: 0.9207 - val_mean_io_u_21: 0.4006\n",
            "Epoch 15/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.1756 - mean_io_u_21: 0.3750 - val_loss: 0.9787 - val_mean_io_u_21: 0.4018\n",
            "Epoch 16/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1730 - mean_io_u_21: 0.3750 - val_loss: 1.0209 - val_mean_io_u_21: 0.4019\n",
            "Epoch 17/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.1704 - mean_io_u_21: 0.3750 - val_loss: 0.9516 - val_mean_io_u_21: 0.4013\n",
            "Epoch 18/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.1678 - mean_io_u_21: 0.3750 - val_loss: 1.0321 - val_mean_io_u_21: 0.4020\n",
            "Epoch 19/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.1657 - mean_io_u_21: 0.3750 - val_loss: 0.9582 - val_mean_io_u_21: 0.4025\n",
            "Epoch 20/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1629 - mean_io_u_21: 0.3750 - val_loss: 0.9367 - val_mean_io_u_21: 0.4030\n",
            "Epoch 21/500\n",
            "399/399 [==============================] - 5s 13ms/step - loss: 0.1607 - mean_io_u_21: 0.3750 - val_loss: 1.0633 - val_mean_io_u_21: 0.4023\n",
            "Epoch 22/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1578 - mean_io_u_21: 0.3750 - val_loss: 0.9376 - val_mean_io_u_21: 0.4037\n",
            "Epoch 23/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1562 - mean_io_u_21: 0.3750 - val_loss: 1.1150 - val_mean_io_u_21: 0.4031\n",
            "Epoch 24/500\n",
            "399/399 [==============================] - 5s 12ms/step - loss: 0.1552 - mean_io_u_21: 0.3750 - val_loss: 1.0752 - val_mean_io_u_21: 0.4030\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01f0eb5670>"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "CQxLKUTNLUne"
      },
      "outputs": [],
      "source": [
        "# validation_volumes_T1_processed = validation_volumes_T1.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2], 1])\n",
        "# validation_labels_processed = validation_labels.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_volumes_T1_processed = validation_volumes_T1.reshape([-1, PATCH_SIZE[0], PATCH_SIZE[1], 1])\n",
        "validation_labels_processed = validation_labels.reshape([-1, PATCH_SIZE[0], PATCH_SIZE[1]])\n",
        "validation_labels_processed=tf.keras.utils.to_categorical(validation_labels_processed, num_classes=4, dtype='float32')"
      ],
      "metadata": {
        "id": "AXV0b6EJrwHI"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_volumes_T1 = validation_volumes_T1[1]\n",
        "testing_labels = validation_labels[1]\n",
        "testing_volumes_T1_processed = testing_volumes_T1.reshape([-1, PATCH_SIZE[0], PATCH_SIZE[1], 1])\n",
        "testing_labels_processed = testing_labels.reshape([-1, PATCH_SIZE[0], PATCH_SIZE[1]])\n",
        "# testing_labels_processed=tf.keras.utils.to_categorical(testing_labels_processed, num_classes=4, dtype='float32')"
      ],
      "metadata": {
        "id": "-qa4MnJE-R-2"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_volumes_T1 = validation_volumes_T1[1]\n",
        "testing_labels = validation_labels[1]\n",
        "testing_volumes_T1_processed = testing_volumes_T1.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2], 1])\n",
        "testing_labels_processed = testing_labels.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2]])"
      ],
      "metadata": {
        "id": "r6acnrqpLI7G"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = get_unet4(\n",
        "    img_size=(IMAGE_SIZE[1], IMAGE_SIZE[2]),\n",
        "    n_classes=N_CLASSES,\n",
        "    n_input_channels=N_INPUT_CHANNELS)\n",
        "unet.compile(optimizer=OPTIMISER, loss=LOSS)\n",
        "unet.load_weights(MODEL_FNAME_PATTERN)"
      ],
      "metadata": {
        "id": "r4P5iH4bMwfj"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "mh9LurKfsIG5"
      },
      "outputs": [],
      "source": [
        "def pred_val_data(x)  :\n",
        "  # creates probability map of each label for all volumes\n",
        "  #prediction = unet.predict(x=testing_volumes_processed)\n",
        "  prediction = unet.predict(x)\n",
        "  # print(np.unique(prediction))\n",
        "  # print(prediction.shape)\n",
        "\n",
        "  prediction = np.argmax(prediction, axis=3)\n",
        "\n",
        "  # plt.axis('off')\n",
        "  # plt.imshow(prediction[:, :, 150])\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csfe_0Fr1l7J",
        "outputId": "6ca4748f-3216-49f4-abd5-840d31b8d040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction = pred_val_data(testing_volumes_T1_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OfZVPXssOdI",
        "outputId": "58cb02f9-78f1-4ba7-d711-5c14b5f4720d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medpy\n",
            "  Downloading MedPy-0.4.0.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from medpy) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from medpy) (1.21.6)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from medpy) (2.2.1)\n",
            "Building wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp38-cp38-linux_x86_64.whl size=753423 sha256=b345fbb64c15f7ed64336bca696ae5b233e5405f1c5e19ed79dcd830e77bd3ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/38/7d/e0b8bcb2770f779a93cab5ab7fa6dd344011e1278cb90cab86\n",
            "Successfully built medpy\n",
            "Installing collected packages: medpy\n",
            "Successfully installed medpy-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install medpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "nGRuOOSosQWX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "08a15efa-72ae-40e7-fc35-726f8e8d4e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice coefficient class 0 equal to  0.99\n",
            "Dice coefficient class 1 equal to  0.76\n",
            "Dice coefficient class 2 equal to  0.88\n",
            "Dice coefficient class 3 equal to  0.74\n",
            "Hausdorff distance class 0 equal to  43.00\n",
            "Hausdorff distance class 1 equal to  87.17\n",
            "Hausdorff distance class 2 equal to  97.10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-254-4b04e5e7fb60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcompute_dice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mcompute_hd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mcompute_ravd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-254-4b04e5e7fb60>\u001b[0m in \u001b[0;36mcompute_hd\u001b[0;34m(prediction, reference, voxel_spacing)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_hd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_spacing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhd_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxelspacing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoxel_spacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Hausdorff distance class {c} equal to {hd_val : .2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/medpy/metric/binary.py\u001b[0m in \u001b[0;36mhd\u001b[0;34m(result, reference, voxelspacing, connectivity)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreal\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mimages\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mtherefore\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msupplied\u001b[0m \u001b[0;32min\u001b[0m \u001b[0many\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \"\"\"\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0mhd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__surface_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxelspacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0mhd2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__surface_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxelspacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhd2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/medpy/metric/binary.py\u001b[0m in \u001b[0;36m__surface_distances\u001b[0;34m(result, reference, voxelspacing, connectivity)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# Note: scipys distance transform is calculated only inside the borders of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;31m#       foreground objects, therefore the input has to be reversed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_transform_edt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mreference_border\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoxelspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0msds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult_border\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/ndimage/morphology.py\u001b[0m in \u001b[0;36mdistance_transform_edt\u001b[0;34m(input, sampling, return_distances, return_indices, distances, indices)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m     \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean_feature_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m     \u001b[0;31m# if requested, calculate the distance transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_distances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from medpy.metric.binary import dc, hd, ravd\n",
        "\n",
        "def compute_dice(prediction, reference) :\n",
        "  for c in np.unique(prediction) :\n",
        "    dsc_val = dc(prediction == c, reference==c)\n",
        "    print(f'Dice coefficient class {c} equal to {dsc_val : .2f}')\n",
        "\n",
        "def compute_hd(prediction, reference, voxel_spacing) :\n",
        "  for c in np.unique(prediction) :\n",
        "    hd_val = hd(prediction == c, reference==c, voxelspacing=voxel_spacing, connectivity=1)\n",
        "    print(f'Hausdorff distance class {c} equal to {hd_val : .2f}')\n",
        "\n",
        "def compute_ravd(prediction, reference) :\n",
        "  for c in np.unique(prediction) :\n",
        "    ravd_val = ravd(prediction == c, reference==c)\n",
        "    print(f'Dice coefficient class {c} avd {ravd_val : .2f}')\n",
        "\n",
        "compute_dice(prediction, testing_labels_processed)\n",
        "compute_hd(prediction, testing_labels_processed, [1, 1, 1])\n",
        "compute_ravd(prediction, testing_labels_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zls74XLDEMtQ",
        "outputId": "bf6c6063-ca36-4886-d6a2-def7c9f540ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 17ms/step\n",
            "Dice coefficient class 0 equal to  1.00\n",
            "Dice coefficient class 1 equal to  0.72\n",
            "Dice coefficient class 2 equal to  0.89\n",
            "Dice coefficient class 3 equal to  0.90\n",
            "Hausdorff distance class 0 equal to  43.20\n",
            "Hausdorff distance class 1 equal to  50.25\n",
            "Hausdorff distance class 2 equal to  47.46\n",
            "Hausdorff distance class 3 equal to  12.69\n",
            "Dice coefficient class 0 avd -0.00\n",
            "Dice coefficient class 1 avd  0.11\n",
            "Dice coefficient class 2 avd -0.07\n",
            "Dice coefficient class 3 avd  0.11\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "Dice coefficient class 0 equal to  1.00\n",
            "Dice coefficient class 1 equal to  0.71\n",
            "Dice coefficient class 2 equal to  0.90\n",
            "Dice coefficient class 3 equal to  0.87\n",
            "Hausdorff distance class 0 equal to  18.38\n",
            "Hausdorff distance class 1 equal to  23.60\n",
            "Hausdorff distance class 2 equal to  14.46\n",
            "Hausdorff distance class 3 equal to  7.81\n",
            "Dice coefficient class 0 avd  0.00\n",
            "Dice coefficient class 1 avd -0.25\n",
            "Dice coefficient class 2 avd  0.06\n",
            "Dice coefficient class 3 avd -0.15\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "Dice coefficient class 0 equal to  1.00\n",
            "Dice coefficient class 1 equal to  0.73\n",
            "Dice coefficient class 2 equal to  0.91\n",
            "Dice coefficient class 3 equal to  0.84\n",
            "Hausdorff distance class 0 equal to  19.75\n",
            "Hausdorff distance class 1 equal to  18.97\n",
            "Hausdorff distance class 2 equal to  13.19\n",
            "Hausdorff distance class 3 equal to  12.53\n",
            "Dice coefficient class 0 avd  0.00\n",
            "Dice coefficient class 1 avd  0.06\n",
            "Dice coefficient class 2 avd  0.05\n",
            "Dice coefficient class 3 avd -0.16\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "Dice coefficient class 0 equal to  1.00\n",
            "Dice coefficient class 1 equal to  0.83\n",
            "Dice coefficient class 2 equal to  0.92\n",
            "Dice coefficient class 3 equal to  0.88\n",
            "Hausdorff distance class 0 equal to  16.16\n",
            "Hausdorff distance class 1 equal to  30.82\n",
            "Hausdorff distance class 2 equal to  14.18\n",
            "Hausdorff distance class 3 equal to  9.06\n",
            "Dice coefficient class 0 avd -0.00\n",
            "Dice coefficient class 1 avd  0.13\n",
            "Dice coefficient class 2 avd  0.10\n",
            "Dice coefficient class 3 avd -0.15\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "Dice coefficient class 0 equal to  1.00\n",
            "Dice coefficient class 1 equal to  0.85\n",
            "Dice coefficient class 2 equal to  0.91\n",
            "Dice coefficient class 3 equal to  0.85\n",
            "Hausdorff distance class 0 equal to  18.06\n",
            "Hausdorff distance class 1 equal to  41.79\n",
            "Hausdorff distance class 2 equal to  14.97\n",
            "Hausdorff distance class 3 equal to  9.27\n",
            "Dice coefficient class 0 avd -0.00\n",
            "Dice coefficient class 1 avd  0.07\n",
            "Dice coefficient class 2 avd  0.07\n",
            "Dice coefficient class 3 avd -0.13\n",
            "Average Dice, HD, and RAVD for class 0 is 0.9968434905957103,23.108276121712674, and -0.00020067656874027078\n",
            "Average Dice, HD, and RAVD for class 1 is 0.7678567361496974,33.08622527108477, and 0.024065663997430382\n",
            "Average Dice, HD, and RAVD for class 2 is 0.9054382345474519,20.84941134994923, and 0.04109185605301526\n",
            "Average Dice, HD, and RAVD for class 3 is 0.8680400159540372,10.271558987226193, and -0.0955998057148713\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from medpy.metric.binary import dc, hd, ravd\n",
        "\n",
        "def compute_dice(prediction, reference) :\n",
        "  dice_scores = np.zeros((1,4))\n",
        "  for c in np.unique(prediction) :\n",
        "    dsc_val = dc(prediction == c, reference==c)\n",
        "    dice_scores[0,c] = dsc_val\n",
        "    print(f'Dice coefficient class {c} equal to {dsc_val : .2f}')\n",
        "  return dice_scores\n",
        "\n",
        "def compute_hd(prediction, reference, voxel_spacing) :\n",
        "  hd_scores = np.zeros((1,4))\n",
        "  for c in np.unique(prediction) :\n",
        "    hd_val = hd(prediction == c, reference==c, voxelspacing=voxel_spacing, connectivity=1)\n",
        "    hd_scores[0,c] = hd_val\n",
        "    print(f'Hausdorff distance class {c} equal to {hd_val : .2f}')\n",
        "  return hd_scores\n",
        "\n",
        "def compute_ravd(prediction, reference) :\n",
        "  ravd_scores = np.zeros((1,4))\n",
        "  for c in np.unique(prediction) :\n",
        "    ravd_val = ravd(prediction == c, reference==c)\n",
        "    ravd_scores[0,c] = ravd_val\n",
        "    print(f'Dice coefficient class {c} avd {ravd_val : .2f}')\n",
        "  return ravd_scores\n",
        "\n",
        "# compute_dice(prediction, testing_labels_processed)\n",
        "# compute_hd(prediction, testing_labels_processed, [1, 1, 1])\n",
        "# compute_ravd(prediction, testing_labels_processed)\n",
        "\n",
        "dice_list=np.zeros((len(validation_volumes_T1),4))\n",
        "hd_list=np.zeros((len(validation_volumes_T1),4))\n",
        "ravd_list=np.zeros((len(validation_volumes_T1),4))\n",
        "\n",
        "for i in range(0,len(validation_volumes_T1)):\n",
        "\n",
        "  testing_volumes_T1=validation_volumes_T1[i]\n",
        "  testing_labels=validation_labels[i]\n",
        "  testing_volumes_T1_processed = testing_volumes_T1.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2], 1])\n",
        "  testing_labels_processed = testing_labels.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2]])\n",
        "  prediction = pred_val_data(testing_volumes_T1_processed)\n",
        "\n",
        "  dice_list[i,:] = compute_dice(prediction, testing_labels_processed)\n",
        "  hd_list[i,:] = compute_hd(prediction, testing_labels_processed, [1, 1, 1])\n",
        "  ravd_list[i,:] = compute_ravd(prediction, testing_labels_processed)\n",
        "\n",
        "dice_total=dice_list.sum(axis=0)\n",
        "hd_total=hd_list.sum(axis=0)\n",
        "ravd_total=ravd_list.sum(axis=0)\n",
        "\n",
        "for i in range(0,4):\n",
        "  print(\"Average Dice, HD, and RAVD for class {} is {},{}, and {}\".format(i,dice_total[i]/len(validation_volumes_T1),hd_total[i]/len(validation_volumes_T1),ravd_total[i]/len(validation_volumes_T1)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mn-yTPP7v5bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsir_ZT9HfJL"
      },
      "outputs": [],
      "source": [
        "dice_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e2ozfmWHsAb"
      },
      "outputs": [],
      "source": [
        "hd_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIKZnqp4Htzw"
      },
      "outputs": [],
      "source": [
        "ravd_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA0ZlghiHQTl"
      },
      "outputs": [],
      "source": [
        "for i in range(0,4):\n",
        "  print(\"Average Dice, HD, and RAVD for class {} is {},{}, and {}\".format(i,dice_total[i]/len(validation_volumes_T1),hd_total[i]/len(validation_volumes_T1),ravd_total[i]/len(validation_volumes_T1)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}